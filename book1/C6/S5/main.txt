Presentadora: Bienvenidos a esta conversación especial. Nos acompaña Yuval Noah Harari, historiador y autor de renombrados libros como Sapiens y Homo Deus, que fue muy enfático sobre los riesgos existenciales que la IA representa para la humanidad. Yuval, gracias por estar aquí.
Yuval Noah Harari: Es un placer; gracias por la invitación.
Presentadora: En tus últimos comentarios, te referiste a que la IA supone un peligro para la humanidad. ¿Podrías explicarnos cómo llegaste a esa conclusión?
Yuval Noah Harari: La IA es la primera tecnología en la historia que puede tomar decisiones de manera autónoma, y eso cambia las reglas del juego. En el pasado, las tecnologías eran herramientas controladas por los humanos: la IA tiene el potencial de tomar decisiones que impacten de modo directo en nuestra vida cotidiana, desde el contenido que consumimos hasta decisiones más profundas como nuestra salud o interacciones políticas. Mi preocupación es que avanzamos tecnológicamente sin tener las regulaciones necesarias que garanticen que estas decisiones resulten éticas y seguras.
Presentadora: Mencionaste que ese poder quizás suponga una amenaza para las democracias. ¿Cómo te parece que la IA afecta ese ámbito?
Yuval Noah Harari: La democracia depende de la conversación pública libre y honesta. Si las IA pueden manipular esas conversaciones o incluso generar discursos políticos, se corre el riesgo de que los ciudadanos pierdan la capacidad de discernir qué es real y qué, no. En regímenes autoritarios, el control de la información siempre fue una herramienta clave. Con IA, las democracias podrían resultar aún más vulnerables a la manipulación masiva. Imagínate interactuar en redes sociales, convencido de estar debatiendo con un humano cuando en realidad es una IA diseñada para influir en tus opiniones políticas. Eso, sin duda, marca el final de la democracia como la conocemos.
Presentadora: Además de los riesgos para la política, también advertiste sobre cómo la IA afectaría el trabajo y la economía global.
Yuval Noah Harari: Exactamente. Uno de los riesgos más graves que planteo es que muchas personas se queden sin empleo, no temporalmente, sino de forma estructural. La IA puede reemplazar a millones de trabajadores sin que estos tengan las habilidades para adaptarse a un nuevo mercado laboral. Eso no solo crearía una crisis económica, sino también psicológica y social: las personas podrían sentirse inútiles dentro del sistema.
Presentadora: En uno de tus artículos en The New York Times, advertiste que la IA podría hacer más que solo reemplazar empleos. Mencionaste que podría manipular nuestras emociones y decisiones políticas. ¿Cómo sería ese escenario?
Yuval Noah Harari: Un escenario inquietante es que la IA podría dominar la creación de narrativas, lo cual es extremadamente poderoso. La historia humana está fundamentada en las narrativas que compartimos y en cómo moldean nuestras decisiones colectivas. Imaginen un mundo donde la mayoría de las historias, noticias e incluso conversaciones personales que vemos y escuchamos son generadas por IA, sin que lo sepamos. La capacidad de influir en elecciones, opiniones e incluso la identidad cultural sería enorme. No sabríamos si estamos hablando con una persona real o con una máquina diseñada para influenciarnos.
Presentadora: Eso suena como una amenaza real para la integridad de nuestras sociedades. ¿Qué soluciones propones para mitigar este tipo de riesgos?
Yuval Noah Harari: La clave está en regular. No podemos simplemente confiar en las empresas tecnológicas para que hagan lo correcto. Como expliqué en otras ocasiones, se necesita un marco regulador similar al de la industria farmacéutica, donde no se puede lanzar una tecnología sin pasar por pruebas rigurosas y revisiones éticas. También, debemos garantizar que las IA estén alineadas con los valores humanos y no se utilicen para explotar nuestras debilidades psicológicas. Eso incluye proteger la democracia de la manipulación y garantizar que las personas mantengan el control sobre su vida cotidiana.
Presentadora: En otro artículo tuyo, que publicaste en The Economist, hablas de la posible independencia de la IA. ¿Es eso realmente una posibilidad?
Yuval Noah Harari: Vemos que la IA está tomando decisiones autónomas en algunas áreas, y ese es un gran desafío. No es un escenario de ciencia ficción. Por ejemplo, en el campo médico, ya tenemos sistemas de IA que diagnostican enfermedades y deciden tratamientos, y lo hacen mejor que muchos médicos. Pero si dejamos que la IA tome decisiones sin supervisión humana, corremos el riesgo de perder el control sobre aspectos esenciales de nuestra vida. Por eso es imperativo desarrollar estructuras que supervisen y limiten sus capacidades, antes de que sea demasiado tarde.
Presentadora: Muy interesante, Yuval. Permíteme ir ahora a algunas preguntas de la audiencia.
Miembro de la audiencia: Prof. Harari, mencionó que la IA podría manipular nuestras emociones y decisiones políticas. ¿Cómo protegernos, como individuos, de esa manipulación en nuestra vida cotidiana?
Yuval Noah Harari: Excelente pregunta. Lo primero es desarrollar un nivel de alfabetización digital más alto: aprender a cuestionar lo que consumimos en línea, verificar las fuentes y entender que no todo lo que aparece en nuestras redes sociales es real. También debemos exigir transparencia a las plataformas tecnológicas, asegurándonos de que indiquen con claridad, si un contenido fue generado por IA. Finalmente, es fundamental fomentar leyes que regulen el uso de estas tecnologías para proteger a los ciudadanos de la manipulación masiva.
Miembro de la audiencia: Mi pregunta es algo teórica: ¿la IA podría permitir que sistemas de economía planificada, como el comunismo, funcionen en el futuro?
Yuval Noah Harari: Una cuestión atrapante. En teoría, la IA tiene el potencial de solucionar un problema histórico de las economías planificadas: la falta de información precisa y oportuna. En el pasado, los intentos de planificación centralizada fracasaron porque los gobiernos no podían procesar la enorme cantidad de datos necesarios para tomar decisiones eficientes sobre producción, distribución y consumo.
Con IA, podríamos imaginar un sistema donde algoritmos muy avanzados analicen en tiempo real las necesidades de la población y optimicen los recursos disponibles. Sin embargo, hay problemas básicos que persisten. Uno es la concentración de poder: ¿quién controla la IA que toma estas decisiones? Otro: la falta de flexibilidad de los sistemas centralizados para adaptarse a las preferencias individuales. Aunque la IA podría hacer que la planificación resulte más eficiente, no resolvería los problemas éticos y políticos inherentes al comunismo.
En resumen, es factible que en el futuro la IA logre que la planificación económica sea más viable desde el punto de vista técnico, pero las cuestiones sobre derechos, equidad y control seguirán siendo grandes desafíos.
Miembro de la audiencia: Prof. Harari, habló de regular, pero en un mundo globalizado, ¿cómo coordinar entre países, en especial, si algunos priorizan la innovación sobre la ética?
Yuval Noah Harari: Uno de los mayores desafíos. La IA no conoce fronteras, pero los gobiernos, sí. Si no llegamos a una cooperación global, veremos una carrera armamentista tecnológica, donde los países compitan por desarrollar IA más avanzada sin preocuparse por las implicaciones éticas. Podría ser catastrófico.
Necesitamos algo similar a los acuerdos internacionales sobre armas nucleares. Un marco como ese establecería estándares mínimos para el desarrollo y uso de la IA. Naciones Unidas podría jugar un papel clave, al igual que organizaciones internacionales que trabajan en temas tecnológicos. No será fácil, pero la historia mostró que, frente a desafíos globales, la cooperación internacional es posible, si todos entienden lo que está en juego.
Presentadora: Muchas gracias a todos por sus preguntas. Prof. Harari, fue un placer tenerlo aquí y escuchar sus reflexiones sobre el futuro de la IA y su impacto en la humanidad.
Yuval Noah Harari: Gracias a ustedes. Estas conversaciones son fundamentales para anticiparnos a los retos que nos depara el futuro.
Sinopsis del capítulo VI
En este capítulo, se exploran algunos de los desafíos más urgentes de la economía moderna, desde la corrupción y la gestión de recursos hasta el impacto de la IA y el cambio climático.
La entrevista a Rafael Di Tella examina la economía de la corrupción, explicando cómo la falta de competencia y las industrias bajo control estatal generan rentas fáciles que fomentan prácticas corruptas, afectando la eficiencia económica y debilitando las instituciones. Se analizan distintos enfoques sobre la corrupción, desde la perspectiva de Andrei Shleifer y Robert Vishny, quienes la describen como un impuesto impredecible que desincentiva la inversión, hasta las investigaciones de Paolo Mauro, que muestran su impacto negativo en el crecimiento económico. 
En una conversación con Elinor Ostrom, se profundiza en la gestión de los recursos comunes y el crecimiento sostenible, desafiando la idea de que la tragedia de los comunes es inevitable. Ostrom argumenta que, bajo ciertos arreglos institucionales, las comunidades locales gestionan sus recursos de manera eficiente sin necesidad de intervención estatal centralizada. Se analizan principios como las reglas de Hotelling y Hartwick para la explotación sostenible de recursos no renovables y se presentan casos exitosos como el modelo noruego de administración de ingresos petroleros. La discusión resalta cómo la gobernanza policéntrica puede ser clave para equilibrar la explotación de recursos con la sostenibilidad a largo plazo.
Sócrates y Glaucón abordan el impacto económico del cambio climático, viendo cómo el calentamiento global afecta sectores radicales como la agricultura, la infraestructura y la productividad de las economías. Sócrates enfatiza la necesidad de invertir en energías renovables, mitigar los efectos de la crisis climática y adaptar las economías a nuevos desafíos ambientales. La conversación también cubre los costos económicos de la transición energética, destacando el debate entre la urgencia de reducir emisiones y la realidad de que muchas economías dependen de combustibles fósiles.
En otro diálogo, Sócrates y Glaucón analizan el impacto de la IA en la economía, abordando su potencial para aumentar la productividad, pero también los riesgos asociados a la automatización del empleo, la ampliación de desigualdades y el consumo energético de estas tecnologías. Se intercambia respecto de cómo los LLMs pueden transformar el trabajo y la educación, así como las dificultades que enfrentarán los países en desarrollo para adaptarse a esta nueva era tecnológica. La conversación subraya la importancia de la regulación y la educación para garantizar que los beneficios de la IA se distribuyan equitativamente y no refuercen las brechas existentes.
Concluyendo el capítulo, estos temas se enlazan con la entrevista a Yuval Noah Harari, quien advierte sobre los riesgos de la inteligencia artificial para la democracia, el empleo y la concentración de poder. Harari plantea interrogantes sobre el futuro de la gobernanza en un mundo donde la IA podría manipular la información y redefinir la estructura de la economía global. Destaca la necesidad de regulaciones internacionales y la cooperación entre países para evitar una carrera descontrolada en el desarrollo de IA. A través de estas reflexiones, el capítulo ofrece un análisis integral de los desafíos contemporáneos y las oportunidades para construir un desarrollo más resiliente, justo y sostenible.
